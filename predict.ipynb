{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "da83a09170e7473192d1cb231491bbc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9af11d232c7c48ea9571ac8d733d2a49",
              "IPY_MODEL_1e787864b1d444178a5387a1ecd7a613",
              "IPY_MODEL_ccf2110be0de48b2a93feb857a9e51bb"
            ],
            "layout": "IPY_MODEL_5205cca8bc884c3585308f6cf6dc2a90"
          }
        },
        "9af11d232c7c48ea9571ac8d733d2a49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8cc9f2240534bc3b2f20ddf2799cf7c",
            "placeholder": "​",
            "style": "IPY_MODEL_ac5fbd93948648b1b1fe45c422958874",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "1e787864b1d444178a5387a1ecd7a613": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12881fc78d874d6281ca988d449daf73",
            "max": 8897,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70739f800b4c465f8d05644be0a24deb",
            "value": 8897
          }
        },
        "ccf2110be0de48b2a93feb857a9e51bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e210f78f083a46e98d381b98897183c9",
            "placeholder": "​",
            "style": "IPY_MODEL_82f43f089f7f4ddf8f0ab784e682aea7",
            "value": " 8.90k/8.90k [00:00&lt;00:00, 515kB/s]"
          }
        },
        "5205cca8bc884c3585308f6cf6dc2a90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8cc9f2240534bc3b2f20ddf2799cf7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac5fbd93948648b1b1fe45c422958874": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12881fc78d874d6281ca988d449daf73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70739f800b4c465f8d05644be0a24deb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e210f78f083a46e98d381b98897183c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82f43f089f7f4ddf8f0ab784e682aea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Общие шаги по предсказанию моделью:\n",
        "1. загрузка приватного тестового набора данных\n",
        "2. проведение лемматизации\n",
        "3. создание датасета и токенизация - каждый батч будет содержать токенизированные исходнык слова и токенизированные леммы\n",
        "4. загрузка модели\n",
        "5. создание предсказаний (map_location=torch.device('cpu') - для данной модели попробовал впервые делать предсказания на cpu; до этого на гпу)\n",
        "6. вывод нескольких получившихся слов\n",
        "7. сохранение предсказания"
      ],
      "metadata": {
        "id": "LBNzKL9Y3UYG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfRqD0SFwRpu",
        "outputId": "4250b8a5-7d1c-4b6c-8cff-9af1b0658526"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers pymystem3 git+https://github.com/Koziev/character-tokenizer -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNqjUl4jwj-F",
        "outputId": "9283d9a5-4ff4-4fff-e33e-4fbf0746a521"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for charactertokenizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import charactertokenizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "import re\n",
        "from pymystem3 import Mystem\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import lr_scheduler"
      ],
      "metadata": {
        "id": "jkS8kQiuwj7c"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vowels = 'аеёиоуыэюя'\n",
        "BATCH_SIZE = 128\n",
        "epochs = 9"
      ],
      "metadata": {
        "id": "R4mwRMJiwj40"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_test = pd.read_csv('/content/drive/MyDrive/rucode final/private_test_stresses.txt', header=None)\n",
        "\n",
        "data_test.columns = ['without_stress']"
      ],
      "metadata": {
        "id": "fHe3oig6wj2d"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Лемматизация"
      ],
      "metadata": {
        "id": "fnAJ0MPCxL_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mystem = Mystem()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    token = mystem.lemmatize(text)[0]\n",
        "    return token\n",
        "\n",
        "data_test['lemma'] = data_test['without_stress'].progress_apply(preprocess_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8xyMuXLwjz-",
        "outputId": "907edce4-8ed4-46cc-ee63-b019273dd4f6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing mystem to /root/.local/bin/mystem from http://download.cdn.yandex.net/mystem/mystem-3.1-linux-64bit.tar.gz\n",
            "100%|██████████| 294252/294252 [00:27<00:00, 10757.77it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, without_stress, lemma, targets=None, max_length=40):\n",
        "\n",
        "        self.tokenizer = charactertokenizer.CharacterTokenizer.from_pretrained('inkoziev/charllama-35M')\n",
        "        self.max_length = max_length\n",
        "\n",
        "        without_stress = [str(item) for item in without_stress]\n",
        "        self.without_stress = self.tokenizer(without_stress, return_tensors='pt', padding='max_length', max_length=max_length, truncation=True)[\"input_ids\"]\n",
        "\n",
        "        lemmas = [str(item) for item in lemma]\n",
        "        self.lemmas = self.tokenizer(lemmas, return_tensors='pt', padding='max_length', max_length=max_length, truncation=True)[\"input_ids\"]\n",
        "\n",
        "        if targets is not None:\n",
        "            targets_int = [torch.tensor([int(digit) for digit in target]) for target in targets]\n",
        "            targets_tensor = torch.stack(targets_int)\n",
        "            self.targets = targets_tensor.numpy()\n",
        "\n",
        "        else:\n",
        "            self.targets = None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.without_stress)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.targets is not None:\n",
        "            return (self.without_stress[idx], self.lemmas[idx]), self.targets[idx]\n",
        "        else:\n",
        "            return (self.without_stress[idx], self.lemmas[idx])"
      ],
      "metadata": {
        "id": "VB1KeF-nwjxN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = CustomDataset(data_test['without_stress'].values, data_test['lemma'].values)\n",
        "\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "da83a09170e7473192d1cb231491bbc9",
            "9af11d232c7c48ea9571ac8d733d2a49",
            "1e787864b1d444178a5387a1ecd7a613",
            "ccf2110be0de48b2a93feb857a9e51bb",
            "5205cca8bc884c3585308f6cf6dc2a90",
            "c8cc9f2240534bc3b2f20ddf2799cf7c",
            "ac5fbd93948648b1b1fe45c422958874",
            "12881fc78d874d6281ca988d449daf73",
            "70739f800b4c465f8d05644be0a24deb",
            "e210f78f083a46e98d381b98897183c9",
            "82f43f089f7f4ddf8f0ab784e682aea7"
          ]
        },
        "id": "G1_cWE2zxSrP",
        "outputId": "1685ebea-e5f1-44b6-fce0-360cfb140e5d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/8.90k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da83a09170e7473192d1cb231491bbc9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class StressModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "        super(StressModel, self).__init__()\n",
        "\n",
        "        self.lstm_layer_1 = nn.Sequential(\n",
        "            nn.Embedding(vocab_size, embedding_dim),\n",
        "            nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True, num_layers=2), # увеличение num_layers не дало результатов\n",
        "        )\n",
        "\n",
        "        self.lstm_layer_2 = nn.Sequential(\n",
        "            nn.Embedding(vocab_size, embedding_dim),\n",
        "            nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True, num_layers=2), # увеличение num_layers не дало результатов\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim * 4, 1)\n",
        "        self.dropout = nn.Dropout(0.05) # возможно нужно увеличить Dropout\n",
        "\n",
        "\n",
        "    def forward(self, batch):\n",
        "        stress, lemma = batch\n",
        "        stress, lemma = stress.to(device), lemma.to(device)\n",
        "\n",
        "        stress_batch, _ = self.lstm_layer_1(stress)\n",
        "        stress_out = self.dropout(stress_batch)\n",
        "\n",
        "        lemma_batch, _ = self.lstm_layer_2(lemma)\n",
        "        lemma_out = self.dropout(lemma_batch)\n",
        "\n",
        "        combined_tensor = torch.cat([stress_out, lemma_out], dim=2)\n",
        "        output = self.fc(combined_tensor)\n",
        "        return output"
      ],
      "metadata": {
        "id": "IW1tLXXCxSo4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cpu'\n",
        "model = torch.load('/content/drive/MyDrive/rucode final/best_model(70-110).pth', map_location=torch.device('cpu'))\n",
        "# model.to(device)"
      ],
      "metadata": {
        "id": "CxBRrAAaxSl1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.parameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-PviRvGxSic",
        "outputId": "a6dc3a74-7784-4f84-98c5-ca10963688f1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of StressModel(\n",
              "  (lstm_layer_1): Sequential(\n",
              "    (0): Embedding(658, 70)\n",
              "    (1): LSTM(70, 110, num_layers=2, batch_first=True, bidirectional=True)\n",
              "  )\n",
              "  (lstm_layer_2): Sequential(\n",
              "    (0): Embedding(658, 70)\n",
              "    (1): LSTM(70, 110, num_layers=2, batch_first=True, bidirectional=True)\n",
              "  )\n",
              "  (fc): Linear(in_features=440, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.05, inplace=False)\n",
              ")>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params_count = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'Number of trainable parameters: {params_count}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVZApjJJyWuP",
        "outputId": "764bae56-122b-40e8-d2ff-a8b58e281480"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of trainable parameters: 997201\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def post_process_output(outputs):\n",
        "    \"\"\"Convert the outputs into a one-hot format with a single '1' for the max value.\"\"\"\n",
        "    max_indices = outputs.argmax(dim=1)\n",
        "    one_hot = torch.zeros_like(outputs)\n",
        "    one_hot[torch.arange(outputs.size(0)), max_indices] = 1.0\n",
        "    return one_hot.float()"
      ],
      "metadata": {
        "id": "WRtihnUmyao8"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---  with post process  ---\n",
        "def get_predictions(model, dataloader, device):\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs in tqdm(dataloader):\n",
        "\n",
        "            outputs = model(inputs).squeeze(2)\n",
        "            predicted = post_process_output(outputs)\n",
        "\n",
        "            all_predictions.extend(predicted.cpu().numpy().tolist())\n",
        "\n",
        "    return all_predictions"
      ],
      "metadata": {
        "id": "xTnZxx38yIZO"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = get_predictions(model, test_dataloader, device) # время на получение предсказаний на cpu: ~17 минут, на gpu: ~1-2 минуты, до этого всегда запускали на gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAJvK4YByIWk",
        "outputId": "5c569591-51af-4336-d3e4-24d93015469b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2299/2299 [17:00<00:00,  2.25it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_test['predicted'] = predictions"
      ],
      "metadata": {
        "id": "x04CidN5yIUE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# расстановка ударений в получившихся словах\n",
        "def add_stress(arr, word):\n",
        "    arr = arr[:len(word)]\n",
        "    new_word = ''.join([char + '^' if arr[i] == 1.0 else char for i, char in enumerate(word)])\n",
        "    return new_word"
      ],
      "metadata": {
        "id": "7CQWiC5zyIRc"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_series = pd.Series([add_stress(arr, word) for arr, word in zip(data_test['predicted'], data_test['without_stress'])])\n",
        "data_test['predicted'] = result_series"
      ],
      "metadata": {
        "id": "nslj10XAyIOd"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_test = data_test['predicted'].values.tolist()"
      ],
      "metadata": {
        "id": "gR9dfkpxxRp8"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# посмотри на получившиеся слова с ударениями\n",
        "import random\n",
        "random_items = random.sample(full_test, 20)\n",
        "print(random_items)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SV6N0QCfwjuU",
        "outputId": "fe074778-719a-4670-8bb8-597c4caea538"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['прикипи^м', 'выпора^жнивавши', 'бронхоадени^ты', 'опосты^лев', 'заморо^сивши', 'хле^бные', 'продыми^ла', 'помолоде^в', 'вы^говорами', 'сверне^м', 'переклю^ют', 'пыря^ет', 'ге^ную', 'зали^занный', 'ме^ртвенными', 'проковырну^ла', 'абзе^тцер', 'потли^востью', 'по^шлину', 'нагримиро^вывалось']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# если нужно, создаем посылку\n",
        "\n",
        "# with open('/content/sample_data/privateTest+model(70-110).txt', 'w', encoding='utf-8') as f:\n",
        "#     for item in full_test:\n",
        "#         f.write(\"%s\\n\" % item)"
      ],
      "metadata": {
        "id": "HCh7TtRvz5YG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}